{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 520 ms, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_c = pd.read_csv('input/challenges.csv')\n",
    "df_s = pd.read_csv('input/submissions.csv', parse_dates=['created_at']).sort_values('created_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of duplicate challenges which were featured in various other contests. I remove them and update the information about their group and subgroup. I also calculate percentage of solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanupChallenges():\n",
    "    cnt = df_c['challenge_id'].value_counts()\n",
    "    df_c['cnt'] = df_c['challenge_id'].apply(lambda x: cnt[x])\n",
    "    \n",
    "    data = []\n",
    "    for k, v in df_c[df_c['cnt'] > 1].groupby('challenge_id'):\n",
    "        contests = v['contest_id'].tolist()\n",
    "        contest = 'c8ff662c97d345d2' if 'c8ff662c97d345d2' in contests else contests[0]\n",
    "        data.append([\n",
    "            k, contest, v['domain'].max(), v['subdomain'].max(), v['difficulty'].max(), \n",
    "            v['solved_submission_count'].sum(), v['solved_submission_count'].sum(), 1\n",
    "        ])\n",
    "    \n",
    "    return pd.concat([df_c[df_c['cnt'] == 1], pd.DataFrame(data, columns=df_c.columns)]).drop('cnt', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_c = cleanupChallenges()\n",
    "df_c['pct'] = df_c['solved_submission_count'] / df_c['total_submissions_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped languages together (didn't use that information) and dropped the `contest_id` (have not seen a reson for using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_map = {\n",
    "    'python3': 'python',\n",
    "    'pypy3': 'python',\n",
    "    'pypy': 'python',\n",
    "    'java8': 'java',\n",
    "    'mysql': 'sql',\n",
    "    'oracle': 'sql',\n",
    "    'tsql': 'sql',\n",
    "    'db2': 'sql',\n",
    "    'cpp14': 'cpp',\n",
    "    'text_pseudo': 'text',\n",
    "    'sbcl': 'lisp',\n",
    "    'clisp': 'lisp',\n",
    "    '[\"html\", \"js\", \"css\"]': 'javascript',\n",
    "    'coffeescript': 'javascript'\n",
    "}\n",
    "df_s['language'] = df_s['language'].apply(lambda x: lang_map.get(x, x))\n",
    "df_s.drop('contest_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The main idea** behind the model was to construct the graph of people coming from one problem to another problem and use the probability of moving between the nodes for selecting the best problems. So I grouped users together, sorted their usage time and created an array of problems they solved (`[p1, p2, p3, ... pn]`. Now I had tuples of `(p1, p2)` and so on (slightly different because I had the requirement that the second value in the tuple is in the list of accepted challenges) and used these data to calculate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getProgress():\n",
    "    hacker_info = {}\n",
    "    for hacker_id, tbl in df_s.groupby('hacker_id'):\n",
    "        order = []\n",
    "        for _, row in tbl.iterrows():\n",
    "            chall_id, lang, solved = row['challenge_id'], row['language'], row['solved']\n",
    "            order.append((chall_id, lang, solved))\n",
    "\n",
    "        hacker_info[hacker_id] = order\n",
    "    return hacker_info\n",
    "\n",
    "def getTuples(arr):\n",
    "    res = []\n",
    "    for i in xrange(len(arr) - 1):\n",
    "        for j in xrange(i + 1, len(arr)):\n",
    "            if arr[j] in submission_ids_set:\n",
    "                res.append((arr[i], arr[j]))\n",
    "                break\n",
    "    return res\n",
    "\n",
    "def getStats():\n",
    "    stats = defaultdict(list)\n",
    "    for v in getProgress().itervalues():\n",
    "        for prev_ids, next_id in getTuples([i[0] for i in v]):\n",
    "            stats[prev_ids].append(next_id)\n",
    "\n",
    "    return {k: Counter(v) for k, v in stats.iteritems()}\n",
    "\n",
    "def cnt_to_df(cnt):\n",
    "    return pd.DataFrame([(k, v) for k, v in cnt.iteritems()], columns=['qID', 'num']).sort_values('num', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hacker_ids = df_s['hacker_id'].unique().tolist()\n",
    "submission_ids = df_c[df_c['contest_id'] == 'c8ff662c97d345d2']['challenge_id'].tolist()\n",
    "submission_ids_set = set(submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 s, sys: 483 ms, total: 46 s\n",
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problem_dict_stats = getStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateChallengesUserInfo():\n",
    "    info_solved, info_tried = {}, {}\n",
    "    for k, v in df_s.groupby('hacker_id'):\n",
    "        solved = set((v[v['solved'] == 1])['challenge_id'].tolist())\n",
    "        tried  = set((v[v['solved'] == 0])['challenge_id'].tolist()) - solved\n",
    "        info_solved[k] = solved\n",
    "        info_tried[k]  = tried\n",
    "    return info_solved, info_tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 122 ms, total: 16.9 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_dict_solved, user_dict_tried = generateChallengesUserInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_g = df_s.merge(df_c, how='left', on='challenge_id')[['hacker_id', 'contest_id', 'challenge_id', 'language', 'solved', 'domain', 'subdomain', 'difficulty', 'pct']]\n",
    "df_g.fillna('unknown', inplace=True)\n",
    "df_c.fillna('unknown', inplace=True)\n",
    "\n",
    "def getMostCommon():\n",
    "    most_common = {}\n",
    "    for k, v in df_g[(df_g['contest_id'] == 'c8ff662c97d345d2') & (df_g['solved'] == 1)].groupby(['domain', 'subdomain']):\n",
    "        most_common[k] = [sId for sId, cnt in Counter(v['challenge_id'].tolist()).most_common(30)]\n",
    "    return most_common\n",
    "\n",
    "most_common = getMostCommon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDomSubdom(probID):\n",
    "    tmp = (df_c[df_c['challenge_id'] == probID])[['domain', 'subdomain']].head(1)\n",
    "    return (tmp['domain'].values[0], tmp['subdomain'].values[0])\n",
    "\n",
    "most_popular_challenges = df_g[(df_g['contest_id'] == 'c8ff662c97d345d2') & (df_g['solved'] == 1)].groupby('challenge_id').count()['hacker_id'].sort_values(ascending=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_solved = df_s.groupby('hacker_id').last()['challenge_id']\n",
    "\n",
    "data = []\n",
    "for hacker_id in hacker_ids:\n",
    "    last_problem = last_solved.loc[hacker_id]\n",
    "    user_solved  = user_dict_solved[hacker_id]\n",
    "    user_tried   = user_dict_tried[hacker_id]\n",
    "    if last_problem in problem_dict_stats:\n",
    "        probs        = problem_dict_stats[last_problem]\n",
    "\n",
    "        tmp_df = cnt_to_df(probs)\n",
    "        tmp_df = tmp_df[~tmp_df['qID'].isin(user_solved)]\n",
    "\n",
    "        best_questions = tmp_df.head(10)['qID'].tolist()\n",
    "        if len(best_questions) < 10:\n",
    "            best_questions += [el for el in most_popular_challenges if el not in user_solved][:(10 - len(best_questions))]\n",
    "            \n",
    "#             add = [el for el in most_common[getDomSubdom(last_problem)] if el not in user_solved]\n",
    "#             best_questions += add[:(10 - len(best_questions))]\n",
    "#             if len(best_questions) < 10:\n",
    "#                 best_questions += [el for el in submission_ids if el not in user_solved][:(10 - len(best_questions))]\n",
    "    else:\n",
    "        #best_questions = [el for el in submission_ids if el not in user_solved][:10]\n",
    "        best_questions = [el for el in most_popular_challenges if el not in user_solved][:10]\n",
    "    \n",
    "    data.append([hacker_id] + best_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(\"output/task_2_11.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- task_2_01 **164.97**\n",
    "- task_2_02 **169.49**\n",
    "- task_2_03 **169.49**\n",
    "- task_2_04 **165.39**\n",
    "- task_2_05 **166.61**\n",
    "- task_2_06 **169.98**\n",
    "- task_2_07 **167.14**\n",
    "- task_2_08 **170.08**\n",
    "- task_2_09 **168.54**\n",
    "- task_2_10 **168.52**\n",
    "- task_2_11 **163.97**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I actually tried reasonable amount of slight modifications of how I select the courses when my recommendation does not return the 10 expected courses. They all either yielded little result of were negative. What I should have done is to investigate what courses have highere probability of being solved by that particular user and improve their probability of being selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
