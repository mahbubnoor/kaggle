{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn import linear_model, ensemble, naive_bayes\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('input/training_dataset.csv')\n",
    "df_2 = pd.read_csv('input/test_dataset.csv')\n",
    "\n",
    "df_1_copy = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove irrelevant fields, merge training and testing set into one dataset (for easier conversion of categorical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df_1['opened']\n",
    "df_1.drop(['click_time', 'clicked', 'open_time', 'unsubscribe_time', 'unsubscribed', 'opened'], axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df_1.copy(), df_2.copy()]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mail_id` and `user_id` are encoded as strings and anonimized. To save space and in order to navigate through them easier I convert them to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ids = df['user_id'].unique().tolist()\n",
    "mail_ids = df['mail_id'].unique().tolist()\n",
    "\n",
    "user_map = {v: k for k, v in enumerate(user_ids)}\n",
    "mail_map = {v: k for k, v in enumerate(mail_ids)}\n",
    "\n",
    "df['user_id'] = df['user_id'].apply(lambda x: user_map[x])\n",
    "df['mail_id'] = df['mail_id'].apply(lambda x: mail_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of users which appears frequently in the dataset. They received many emails and thus either opened or ignored them. I extracted open rate for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = df_1_copy[['user_id', 'opened']].groupby('user_id')\n",
    "user_info = (pd.concat([gb.sum() / gb.count(), gb.count()], axis=1)).reset_index()\n",
    "user_info.columns = ['user_id', 'opened_rate', 'all_num']\n",
    "user_info['user_id'] = user_info['user_id'].apply(lambda x: user_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few fields had timestamp information. Convert them to timestamp (should have done it while reading). These timestamps are not really helpful, so I extracted information about user's age in the system at the time of sending and from the last time he has been seen. Both information is in days.\n",
    "\n",
    "Also converted mail_type category to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamp_fields = ['sent_time', 'last_online', 'hacker_created_at']\n",
    "for el in timestamp_fields:\n",
    "    df[el] = df[el].astype('datetime64[s]')\n",
    "\n",
    "df['age_sent'] = (df['sent_time'] - df['hacker_created_at']) / np.timedelta64(1, 'D')\n",
    "df['last_seen'] = (df['sent_time'] - df['last_online']) / np.timedelta64(1, 'D')\n",
    "\n",
    "df.drop(['mail_type'] + timestamp_fields, axis=1, inplace=True)\n",
    "\n",
    "df['mail_category'] = pd.to_numeric(df['mail_category'].str.split('y_').str.get(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renamed a couple of fields and reordered them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'contest_login_count'          : 'clc_all',\n",
    "    'contest_login_count_1_days'   : 'clc_1',\n",
    "    'contest_login_count_7_days'   : 'clc_7',\n",
    "    'contest_login_count_30_days'  : 'clc_30',\n",
    "    'contest_login_count_365_days' : 'clc_365',\n",
    "    \n",
    "    'contest_participation_count'           : 'cpc_all',\n",
    "    'contest_participation_count_1_days'    : 'cpc_1',\n",
    "    'contest_participation_count_7_days'    : 'cpc_7',\n",
    "    'contest_participation_count_30_days'   : 'cpc_30',\n",
    "    'contest_participation_count_365_days'  : 'cpc_365',\n",
    "    \n",
    "    'submissions_count'         : 'subm_all',\n",
    "    'submissions_count_1_days'  : 'subm_1',\n",
    "    'submissions_count_7_days'  : 'subm_7',\n",
    "    'submissions_count_30_days' : 'subm_30',\n",
    "    'submissions_count_365_days': 'subm_365',\n",
    "    \n",
    "    'submissions_count_contest'         : 'subm_c_all',\n",
    "    'submissions_count_contest_1_days'  : 'subm_c_1',\n",
    "    'submissions_count_contest_7_days'  : 'subm_c_7',\n",
    "    'submissions_count_contest_30_days' : 'subm_c_30',\n",
    "    'submissions_count_contest_365_days': 'subm_c_365',\n",
    "    \n",
    "    'submissions_count_master'         : 'subm_m_all',\n",
    "    'submissions_count_master_1_days'  : 'subm_m_1',\n",
    "    'submissions_count_master_7_days'  : 'subm_m_7',\n",
    "    'submissions_count_master_30_days' : 'subm_m_30',\n",
    "    'submissions_count_master_365_days': 'subm_m_365',\n",
    "    \n",
    "    'ipn_count'         : 'ipn_all',\n",
    "    'ipn_count_1_days'  : 'ipn_1',\n",
    "    'ipn_count_7_days'  : 'ipn_7',\n",
    "    'ipn_count_30_days' : 'ipn_30',\n",
    "    'ipn_count_365_days': 'ipn_365',\n",
    "    \n",
    "    'ipn_read'         : 'ipnr_all',\n",
    "    'ipn_read_1_days'  : 'ipnr_1',\n",
    "    'ipn_read_7_days'  : 'ipnr_7',\n",
    "    'ipn_read_30_days' : 'ipnr_30',\n",
    "    'ipn_read_365_days': 'ipnr_365',\n",
    "    \n",
    "    'forum_comments_count' : 'forum_reply',\n",
    "    'forum_count'          : 'forum_cnt',\n",
    "    'forum_expert_count'   : 'forum_exp',\n",
    "    'forum_questions_count': 'forum_quest',\n",
    "    'hacker_confirmation'  : 'confirmed',\n",
    "    'hacker_timezone'      : 'timezone',\n",
    "    'mail_category'        : 'mail_cat'\n",
    "}, inplace=True)\n",
    "\n",
    "df = df[[\n",
    "    'user_id', 'age_sent', 'last_seen', 'mail_id', 'mail_cat', 'timezone', 'confirmed',\n",
    "    \n",
    "    'forum_reply', 'forum_cnt', 'forum_exp', 'forum_quest',\n",
    "    \n",
    "    'clc_all', 'clc_1', 'clc_7', 'clc_30', 'clc_365',\n",
    "    'cpc_all', 'cpc_1', 'cpc_7', 'cpc_30', 'cpc_365',\n",
    "    'subm_all', 'subm_1', 'subm_7', 'subm_30', 'subm_365',\n",
    "    'subm_c_all', 'subm_c_1', 'subm_c_7', 'subm_c_30', 'subm_c_365',\n",
    "    'subm_m_all', 'subm_m_1', 'subm_m_7', 'subm_m_30', 'subm_m_365',\n",
    "    'ipn_all', 'ipn_1', 'ipn_7', 'ipn_30', 'ipn_365',\n",
    "    'ipnr_all', 'ipnr_1', 'ipnr_7', 'ipnr_30', 'ipnr_365',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cardinality of the categorical variables was too high, so I tried to trim it. I also imputed NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def truncate_categorical(field, num):\n",
    "    tmp = df[field].value_counts()\n",
    "    vals = set(tmp[tmp < num].index.values)\n",
    "\n",
    "    df[field][df[field].isin(vals)] = -1\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truncate_categorical('mail_id', 200);\n",
    "truncate_categorical('timezone', 400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['mail_cat'].fillna(18, inplace=True) # the least popular category\n",
    "df['timezone'].fillna(-1, inplace=True) # group of least popular timezones\n",
    "df['last_seen'].fillna(df['last_seen'].mean(), inplace=True) # mean value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally adding open rate which I calculated almost in the beginning of the notebook. Also calculate percentage of notification rates over some period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.reset_index().merge(user_info, on='user_id', how = 'left').sort_values('index').drop(['index'], 1)\n",
    "df['opened_rate'].fillna(0.5, inplace=True)\n",
    "df['has_opened_rate'] = ~df['all_num'].isnull()\n",
    "df['all_num'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ipn_all_percent'] = (df['ipnr_all'] / df['ipn_all']).fillna(0.5)\n",
    "df['ipn_1_percent']   = (df['ipnr_1']   / df['ipn_1']).fillna(0.5)\n",
    "df['ipn_7_percent']   = (df['ipnr_7']   / df['ipn_7']).fillna(0.5)\n",
    "df['ipn_30_percent']  = (df['ipnr_30']  / df['ipn_30']).fillna(0.5)\n",
    "df['ipn_365_percent'] = (df['ipnr_365'] / df['ipn_365']).fillna(0.5)\n",
    "\n",
    "df.drop(['ipnr_all', 'ipn_all', 'ipnr_1', 'ipn_1', 'ipnr_7', 'ipn_7', 'ipnr_30', 'ipn_30', 'ipnr_365', 'ipn_365'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of fields that follow powerlaw distribution and thus there is very small number of people with a huge numbers. I trim this data and sometimes apply log transofmation to some of the field. I tried various variants of these trimmers with no significant change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['age_sent'] >= df['age_sent'].quantile(0.9)] = df['age_sent'].quantile(0.98)\n",
    "data_arr = [\n",
    "    ('last_seen', 400, 500),\n",
    "    ('forum_reply', 80, 100),\n",
    "    ('forum_cnt', 40, 60),\n",
    "    ('forum_exp', 5, 7),\n",
    "    ('forum_quest', 5, 7),\n",
    "    ('clc_all', 40, 60),\n",
    "    ('clc_365', 40, 60),\n",
    "    ('cpc_all', 100, 120),\n",
    "    ('cpc_7', 20, 30),\n",
    "    ('cpc_30', 50, 60),\n",
    "    ('cpc_365', 100, 110),\n",
    "    ('subm_1', 40, 60),\n",
    "    ('subm_c_1', 40, 50),\n",
    "    ('subm_m_1', 40, 50)\n",
    "]\n",
    "for name, max_val, cap_val in data_arr:\n",
    "    df[df[name] >= max_val] = cap_val\n",
    "\n",
    "def log_transform(x):\n",
    "    return 0 if x == 0 else np.log2(x) + 1\n",
    "    \n",
    "for name in [\n",
    "    'subm_all', 'subm_30', 'subm_365', 'subm_c_all', 'subm_c_7', 'subm_7', 'subm_c_365', 'subm_c_30',\n",
    "    'subm_m_all', 'subm_m_7', 'subm_m_30', 'subm_m_365'\n",
    "]:\n",
    "    df[name] = df[name].apply(log_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally creating dummies from categorical variables, creating X, Y matrices and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x = pd.get_dummies(df, columns=['mail_id', 'mail_cat', 'timezone'])\n",
    "\n",
    "X_train = df_x.values[:len(Y), 1:]\n",
    "y_train = Y.values\n",
    "\n",
    "X_test  = df_x.values[len(Y):, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test  = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that F1 score does not take into account True Negatives, I played with class_weight scores. It actually gave reasonable imporovement. The number 730 was selected after I tried various combinations from 500 to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 3.46 s, total: 3min 1s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weight = 730\n",
    "clf = linear_model.LogisticRegression(class_weight={1: weight, 0: 1000 - weight}, C=0.3)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930146493485192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally changing some of the scores for poeple who almost never opened an email and people who almost always opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_open = 15\n",
    "epsilon = 0.2\n",
    "set_user_open_0 = set(user_info[(user_info['opened_rate'] <= 0 + epsilon) & (user_info['all_num'] > num_open)]['user_id'].tolist())\n",
    "set_user_open_1 = set(user_info[(user_info['opened_rate'] >= 1 - epsilon) & (user_info['all_num'] > num_open)]['user_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_res(row):\n",
    "    if row['user_id'] in set_user_open_0:\n",
    "        return 0\n",
    "    if row['user_id'] in set_user_open_1:\n",
    "        return 1\n",
    "    return row['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.concat([\n",
    "    pd.DataFrame(clf.predict(X_test), columns=['result']),\n",
    "    pd.DataFrame(df_x.loc[len(Y):]['user_id'].reset_index(drop=True))\n",
    "], axis=1)\n",
    "\n",
    "res_df['result']  = res_df['result'].astype(int)\n",
    "res_df['user_id'] = res_df['user_id'].astype(int)\n",
    "res_df['result'] = res_df.apply(change_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_df[['result']].to_csv(\"output_03.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
